#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FX Coding â€” Stage 3b: Clean Retrain Model
-----------------------------------------
Huáº¥n luyá»‡n láº¡i LightGBM vá»›i bá»™ features Ä‘Ã£ Ä‘Æ°á»£c Stage 4L chá»n lá»c
(Ä‘Ã£ loáº¡i bá» noise, giá»¯ láº¡i cÃ¡c feature cÃ³ alpha thá»±c sá»±).

Input:
  - logs/stage2_features.csv       (X)
  - logs/stage3_y.csv              (y)
  - logs/lab_feature_selected.txt  (feature list tá»« Stage 4L)

Output:
  - logs/T4_clean_lightgbm.txt          (model)
  - logs/T4_clean_feature_importance.csv
  - logs/T4_clean_summary.txt
"""

import os
import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report

# ================= CONFIG =================
FEATURE_FILE = "logs/stage2_features.csv"
Y_FILE = "logs/stage3_y.csv"
SELECTED_TXT = "logs/lab_feature_selected.txt"

OUT_MODEL = "logs/T4_clean_lightgbm.txt"
OUT_IMP = "logs/T4_clean_feature_importance.csv"
OUT_SUMMARY = "logs/T4_clean_summary.txt"

SEED = 202
N_JOBS = 28
os.makedirs("logs", exist_ok=True)

# ================= LOAD DATA =================
print("â³ Loading data ...")
X = pd.read_csv(FEATURE_FILE)
y = pd.read_csv(Y_FILE)["y"]

selected = [
    line.strip()
    for line in open(SELECTED_TXT)
    if line.strip() in X.columns
]
if len(selected) == 0:
    raise RuntimeError("KhÃ´ng cÃ³ feature nÃ o match giá»¯a lab_feature_selected.txt vÃ  stage2_features.csv.")

X = X[selected]
print(f"âœ… Using {len(selected)} selected features out of {X.shape[1]}")

# Align lengths
n = min(len(X), len(y))
X, y = X.iloc[:n].reset_index(drop=True), y.iloc[:n].reset_index(drop=True)

X_train, X_valid, y_train, y_valid = train_test_split(
    X, y, test_size=0.1, random_state=SEED, shuffle=True
)

print(f"Train={len(X_train):,} | Valid={len(X_valid):,}")

# ================= LIGHTGBM PARAMS =================
params = dict(
    objective="binary",             # binary classification
    metric="binary_logloss",
    boosting_type="gbdt",
    learning_rate=0.05,
    num_leaves=64,
    feature_fraction=0.9,
    bagging_fraction=0.9,
    bagging_freq=5,
    max_depth=-1,
    n_jobs=N_JOBS,
    verbose=-1,
)

callbacks = [
    lgb.early_stopping(30),
    lgb.log_evaluation(50)
]

# ================= TRAIN MODEL =================
train_data = lgb.Dataset(X_train, label=y_train)
valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)

print("ðŸš€ Training LightGBM clean model ...")
model = lgb.train(
    params,
    train_data,
    num_boost_round=800,
    valid_sets=[valid_data],
    callbacks=callbacks
)

# ================= SAVE MODEL =================
model.save_model(OUT_MODEL)
print(f"âœ… Saved model â†’ {OUT_MODEL}")

# ================= FEATURE IMPORTANCE =================
imp = pd.DataFrame({
    "feature": model.feature_name(),
    "importance": model.feature_importance(importance_type="gain")
}).sort_values("importance", ascending=False)
imp.to_csv(OUT_IMP, index=False)
print(f"âœ… Feature importance saved â†’ {OUT_IMP}")

# ================= VALIDATION METRICS =================
preds = (model.predict(X_valid) > 0.5).astype(int)
acc = accuracy_score(y_valid, preds)
f1 = f1_score(y_valid, preds)
report = classification_report(y_valid, preds)

print(f"\nâœ… Validation ACC={acc:.4f} | F1={f1:.4f}")
print(report)

with open(OUT_SUMMARY, "w") as f:
    f.write(f"Validation ACC={acc:.4f}\nF1={f1:.4f}\n\n")
    f.write(report)

print(f"âœ… Summary saved â†’ {OUT_SUMMARY}")
print("ðŸŽ¯ Stage 3b retrain complete.")