#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage 4.4 â€” Feature Refinement & Quick Retrain (GBPUSD)

Má»¥c tiÃªu:
1. ThÃªm directional / trend-based features tá»« tsfresh feature matrix.
2. Chuáº©n hoÃ¡ dá»¯ liá»‡u (Z-score scaling) Ä‘á»ƒ LightGBM há»c tá»‘t hÆ¡n.
3. Train thá»­ nhanh Ä‘á»ƒ kiá»ƒm tra xem cÃ³ alpha xuáº¥t hiá»‡n (AUC > 0.55).

Input:
    logs/stage4_tsfresh_features_gbpusd.csv
    data/stage3_train_ready.parquet
Output:
    logs/stage4_refined_features_gbpusd.csv
    logs/stage4_refined_model_gbpusd.txt
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timezone
from sklearn.preprocessing import StandardScaler
import lightgbm as lgb
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report

FEATURE_CSV = "logs/stage4_tsfresh_features_gbpusd.csv"
LABEL_FILE  = "data/stage3_train_ready.parquet"
OUT_FEATURE = "logs/stage4_refined_features_gbpusd.csv"
OUT_MODEL   = "logs/stage4_refined_model_gbpusd.txt"

def log(msg: str):
    now = datetime.now(timezone.utc).strftime("[%Y-%m-%d %H:%M:%S UTC]")
    print(f"{now} {msg}", flush=True)

def main():
    log("ğŸš€ Stage 4.4 â€” Feature Refinement & Quick Retrain (GBPUSD)")

    # -----------------------------
    # 1ï¸âƒ£ Load data
    # -----------------------------
    feat = pd.read_csv(FEATURE_CSV, index_col=0, parse_dates=True)
    log(f"ğŸ“¥ Loaded features: {feat.shape}")

    labels = pd.read_parquet(LABEL_FILE)
    labels.index = pd.to_datetime(labels.index, utc=True)
        # Backward compatibility â€” Stage 3 naming
    if "target_label" not in labels.columns:
        labels = labels.rename(columns={
            "lbl_mc_012": "target_label",
            "mask_train": "target_is_trainable",
            "reason": "target_drop_reason"
        })

    labels = labels[["target_label", "target_is_trainable"]].copy()
    labels = labels[labels["target_is_trainable"] == 1]
    
    # Align features (window_end_time) vá»›i label timestamp gáº§n nháº¥t nhÆ°ng <= window_end_time
    feat = feat.sort_index()
    labels = labels.sort_index()

    # DÃ¹ng asof join thay vÃ¬ join trá»±c tiáº¿p
    merged = pd.merge_asof(
        labels.sort_index(),
        feat.sort_index(),
        left_index=True,
        right_index=True,
        direction="nearest",                 # cho phÃ©p khá»›p 2 chiá»u
        tolerance=pd.Timedelta("48H"),       # cho phÃ©p lá»‡ch tá»‘i Ä‘a 2 ngÃ y
    )
    
    print(f"[DEBUG] merged shape: {merged.shape}")
    print(f"[DEBUG] merged time range: {merged.index.min()} â†’ {merged.index.max()}")
    print(f"[DEBUG] NaN ratio: {merged.isna().mean().mean():.3f}")

    # loáº¡i NaN náº¿u cÃ³
    merged = merged.dropna()
    print(f"[DEBUG] merged shape: {merged.shape}")
    print(f"[DEBUG] merged time range: {merged.index.min()} â†’ {merged.index.max()}")
    log(f"ğŸ”— Aligned samples: {merged.shape}")

    X = merged.drop(columns=["target_label", "target_is_trainable"])
    y = merged["target_label"].astype(int)

    # -----------------------------
    # 2ï¸âƒ£ Directional feature creation
    # -----------------------------
    # mean vs last value difference, slope, momentum ratio
    # (approximate trend signals)
    log("â• Adding directional meta-features...")
    X["feat_mean"] = X.mean(axis=1)
    X["feat_std"] = X.std(axis=1)
    X["feat_skew"] = X.skew(axis=1)
    X["feat_kurt"] = X.kurtosis(axis=1)
    X["feat_slope"] = X["feat_mean"].diff().fillna(0)
    X["feat_volratio"] = (X["feat_std"] / (X["feat_mean"].abs() + 1e-6)).fillna(0)

    # -----------------------------
    # 3ï¸âƒ£ Z-score normalization
    # -----------------------------
    log("âš–ï¸ Scaling features (z-score)...")
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(
        scaler.fit_transform(X),
        index=X.index,
        columns=X.columns
    )

    Path("logs").mkdir(exist_ok=True)
    X_scaled.to_csv(OUT_FEATURE)
    log(f"ğŸ’¾ Saved refined features â†’ {OUT_FEATURE} ({X_scaled.shape})")

    # -----------------------------
    # 4ï¸âƒ£ Quick LightGBM training
    # -----------------------------
    log("âš™ï¸ Quick train/validation split...")
    split = int(len(X_scaled) * 0.8)
    X_train, X_valid = X_scaled.iloc[:split], X_scaled.iloc[split:]
    y_train, y_valid = y.iloc[:split], y.iloc[split:]

    params = dict(
        objective="binary",
        metric=["binary_logloss", "auc"],
        learning_rate=0.05,
        num_leaves=64,
        min_data_in_leaf=50,
        feature_fraction=0.8,
        bagging_fraction=0.8,
        bagging_freq=5,
        seed=42,
        n_jobs=28,
    )

    dtrain = lgb.Dataset(X_train, label=y_train)
    dvalid = lgb.Dataset(X_valid, label=y_valid)

    log("ğŸš€ Training LightGBM...")
    model = lgb.train(
        params,
        dtrain,
        valid_sets=[dtrain, dvalid],
        num_boost_round=500,
        callbacks=[lgb.early_stopping(30), lgb.log_evaluation(50)],
    )

    # -----------------------------
    # 5ï¸âƒ£ Evaluate
    # -----------------------------
    preds = model.predict(X_valid)
    auc = roc_auc_score(y_valid, preds)
    preds_bin = (preds > 0.5).astype(int)
    acc = accuracy_score(y_valid, preds_bin)

    log(f"ğŸ“Š Validation AUC: {auc:.4f}")
    log(f"ğŸ“Š Accuracy: {acc:.4f}")
    log("ğŸ” Classification report:")
    print(classification_report(y_valid, preds_bin, target_names=["SHORT(0)", "LONG(1)"]))

    model.save_model(OUT_MODEL)
    log(f"ğŸ’¾ Model saved â†’ {OUT_MODEL}")
    log("âœ… Stage 4.4 completed successfully")


if __name__ == "__main__":
    main()