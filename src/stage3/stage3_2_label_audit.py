#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage 3.2 ‚Äî Label Audit & Integrity Check
-----------------------------------------
Ki·ªÉm tra ch·∫•t l∆∞·ª£ng nh√£n Stage 3.1:
    ‚Ä¢ Ph√¢n ph·ªëi class (balance)
    ‚Ä¢ Autocorrelation ‚Üí xem c√≥ l·∫∑p pattern / bias kh√¥ng
    ‚Ä¢ Ph√¢n b·ªë theo gi·ªù phi√™n (Asia / London / NY)
    ‚Ä¢ T·ª∑ l·ªá choppy (class 1) trong c√°c session

Input:
    data/stage3_labels.parquet
    data/stage2_features_combined.parquet (ƒë·ªÉ l·∫•y timestamp cho session mapping)

Output:
    logs/stage3_label_audit.txt
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

LABEL_FILE = "data/stage3_labels.parquet"
FEATURE_FILE = "data/stage2_features_combined.parquet"
OUT_LOG = "logs/stage3_label_audit.txt"

def log(msg, file=None):
    print(msg)
    if file:
        file.write(msg + "\n")

def session_from_hour(h):
    """Tr·∫£ v·ªÅ session t√™n d·ª±a v√†o UTC hour."""
    if 0 <= h < 7:
        return "Asia"
    elif 7 <= h < 12:
        return "London"
    elif 12 <= h < 20:
        return "NY"
    else:
        return "AfterHours"

def main():
    Path("logs").mkdir(exist_ok=True)
    f = open(OUT_LOG, "w")
    log(f"[{datetime.utcnow()}] üöÄ Stage 3.2 ‚Äî Label QA started", f)

    lbl = pd.read_parquet(LABEL_FILE)
    feat = pd.read_parquet(FEATURE_FILE)
    lbl = lbl.reindex(feat.index)  # ƒë·∫£m b·∫£o index kh·ªõp
    log(f"üì• Loaded labels: {len(lbl):,} rows", f)

    # --- Distribution ---
    dist = lbl["lbl_mc_012"].value_counts(normalize=True).sort_index()
    log("\nüìä Class distribution:", f)
    for k, v in dist.items():
        log(f"   Class {int(k)} ‚Üí {v*100:.2f}%", f)

    # --- Autocorrelation ---
    series = lbl["lbl_mc_012"].fillna(1).astype(float)
    autocorr1 = series.autocorr(lag=1)
    autocorr5 = series.autocorr(lag=5)
    autocorr20 = series.autocorr(lag=20)
    log("\nüîÅ Autocorrelation (to detect label stickiness):", f)
    log(f"   lag=1  ‚Üí {autocorr1:.4f}", f)
    log(f"   lag=5  ‚Üí {autocorr5:.4f}", f)
    log(f"   lag=20 ‚Üí {autocorr20:.4f}", f)

    # --- Session mapping ---
    hours = lbl.index.hour
    lbl["session"] = [session_from_hour(h) for h in hours]
    pivot = lbl.groupby("session")["lbl_mc_012"].value_counts(normalize=True).unstack(fill_value=0)
    log("\nüïí Distribution by session (%):", f)
    log(str((pivot * 100).round(2)), f)

    # --- Summary of choppy periods ---
    choppy_ratio = (lbl["lbl_mc_012"] == 1).mean()
    log(f"\nüåä Overall choppy ratio: {choppy_ratio*100:.2f}%", f)
    choppy_by_session = (lbl[lbl["lbl_mc_012"] == 1].groupby("session").size() / lbl.groupby("session").size()).round(3)
    log("üåç Choppy ratio by session:", f)
    for s, v in choppy_by_session.items():
        log(f"   {s}: {v*100:.1f}%", f)

    # --- Save summary ---
    f.close()
    print(f"üíæ Saved audit log ‚Üí {OUT_LOG}")

if __name__ == "__main__":
    main()